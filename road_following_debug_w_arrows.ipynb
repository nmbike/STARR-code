{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Following Debug "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will debug and adjust the steering settings to allow the jetBot to smoothly run on our track. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Notebook is largely based on the \"live_demo\" notebook that is found in the Sparkfun notebook for road following. It is meant to be a code to help debug your robot/code.\n",
    "#### Modified by the Skonk Works robotics team for the STARR program 02/22/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT!! \n",
    "#### The following code will disable your LED printout showing the IP address of your robot. You MUST run the last cell in this notebook to reenable your LED operations. If something happens during the operation of this notebook, simply reboot your robot, return to this notebook and run the last cell to reenable the functionality of your LED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO NOT run the following two cells again after rebooting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following lines of code will cause your robot to reboot. You will need to type in your password into the text widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ······\n"
     ]
    }
   ],
   "source": [
    "password = getpass.getpass()\n",
    "os.system('echo %s | sudo -S mv  /usr/local/lib/python3.6/dist-packages/jetbot-0.4.0-py3.6.egg/jetbot/apps/stats.py /usr/local/lib/python3.6/dist-packages/jetbot-0.4.0-py3.6.egg/jetbot/apps/stats.py.orig ' % (password))\n",
    "os.system('echo %s | sudo -S reboot ' % (password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will assume that you have already downloaded ``best_steering_model_xy.pth`` to work station as instructed in \"train_model.ipynb\" notebook. Now, you should upload model file to JetBot in to this notebooks's directory. Once that's finished there should be a file named ``best_steering_model_xy.pth`` in this notebook's directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code below to initialize the PyTorch model. This should look very familiar from the training notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Please make sure the file has uploaded fully before calling the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the trained weights from the ``best_steering_model_xy.pth`` file that you uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_maze_model_xy_251.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the model weights are located on the CPU memory execute the code below to transfer to the GPU device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model = model.eval().half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Pre-Processing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now loaded our model, but there's a slight issue. The format that we trained our model doesnt exactly match the format of the camera. To do that, we need to do some preprocessing. This involves the following steps:\n",
    "\n",
    "1. Convert from HWC layout to CHW layout\n",
    "2. Normalize using same parameters as we did during training (our camera provides values in [0, 255] range and training loaded images in [0, 1] range so we need to scale by 255.0\n",
    "3. Transfer the data from CPU memory to GPU memory\n",
    "4. Add a batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We've now defined our pre-processing function which can convert images from the camera format to the neural network input format.\n",
    "\n",
    "The command to display your camera to your notebook is currently commented out so the robot will run more efficiently.\n",
    "If you wish to have the camera display to your notebook uncomment the display command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<traitlets.traitlets.directional_link at 0x7f82e74358>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera()\n",
    "\n",
    "image_widget = ipywidgets.Image()\n",
    "\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "#display(image_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create our robot instance which we'll need to drive the motors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now create LED functions to show which direction our robot is steering. These will be used to test how the robot is interpreting it's scene while remaining stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qwiic_micro_oled\n",
    "cyclops = qwiic_micro_oled.QwiicMicroOled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrow_right():\n",
    "    cyclops.begin()\n",
    "    cyclops.clear(cyclops.PAGE)\n",
    "\n",
    "    cyclops.pixel(62,24)\n",
    "    cyclops.line_v(61,23,3)\n",
    "    cyclops.line_v(60,22,5)\n",
    "    cyclops.line_v(59,21,7)\n",
    "    cyclops.line_v(58,20,9)\n",
    "    cyclops.line_v(57,19,11)\n",
    "    cyclops.line_v(56,18,13)\n",
    "    cyclops.line_v(55,17,15)\n",
    "    cyclops.line_v(54,16,17)\n",
    "    cyclops.line_v(53,15,19)\n",
    "    cyclops.line_v(52,14,21)\n",
    "    cyclops.line_v(51,13,23)\n",
    "    cyclops.line_v(50,12,25)\n",
    "    cyclops.line_v(49,11,27)\n",
    "    cyclops.line_v(48,10,29)\n",
    "    cyclops.line_v(47,9,31)\n",
    "    cyclops.line_v(46,8,33)\n",
    "    cyclops.line_v(45,7,35)\n",
    "    cyclops.line_v(44,6,37)\n",
    "\n",
    "    cyclops.rect_fill(3,16,41,16)\n",
    "\n",
    "    cyclops.display()\n",
    "\n",
    "def arrow_left():\n",
    "    cyclops.begin()\n",
    "    cyclops.clear(cyclops.PAGE)\n",
    "\n",
    "    cyclops.pixel(2,24)\n",
    "    cyclops.line_v(3,23,3)\n",
    "    cyclops.line_v(4,22,5)\n",
    "    cyclops.line_v(5,21,7)\n",
    "    cyclops.line_v(6,20,9)\n",
    "    cyclops.line_v(7,19,11)\n",
    "    cyclops.line_v(8,18,13)\n",
    "    cyclops.line_v(9,17,15)\n",
    "    cyclops.line_v(10,16,17)\n",
    "    cyclops.line_v(11,15,19)\n",
    "    cyclops.line_v(12,14,21)\n",
    "    cyclops.line_v(13,13,23)\n",
    "    cyclops.line_v(14,12,25)\n",
    "    cyclops.line_v(15,11,27)\n",
    "    cyclops.line_v(16,10,29)\n",
    "    cyclops.line_v(17,9,31)\n",
    "    cyclops.line_v(18,8,33)\n",
    "    cyclops.line_v(19,7,35)\n",
    "    cyclops.line_v(20,6,37)\n",
    "\n",
    "    cyclops.rect_fill(20,16,41,16)\n",
    "\n",
    "    cyclops.display()\n",
    "    \n",
    "def arrow_straight():\n",
    "    cyclops.begin()\n",
    "    cyclops.clear(cyclops.PAGE)\n",
    "\n",
    "    cyclops.pixel(62,24)\n",
    "    cyclops.line_v(61,23,3)\n",
    "    cyclops.line_v(60,22,5)\n",
    "    cyclops.line_v(59,21,7)\n",
    "    cyclops.line_v(58,20,9)\n",
    "    cyclops.line_v(57,19,11)\n",
    "    cyclops.line_v(56,18,13)\n",
    "    cyclops.line_v(55,17,15)\n",
    "    cyclops.line_v(54,16,17)\n",
    "    cyclops.line_v(53,15,19)\n",
    "    cyclops.line_v(52,14,21)\n",
    "    cyclops.line_v(51,13,23)\n",
    "    cyclops.line_v(50,12,25)\n",
    "    cyclops.line_v(49,11,27)\n",
    "    cyclops.line_v(48,10,29)\n",
    "    cyclops.line_v(47,9,31)\n",
    "    cyclops.line_v(46,8,33)\n",
    "    cyclops.line_v(45,7,35)\n",
    "    cyclops.line_v(44,6,37)\n",
    "    \n",
    "    cyclops.pixel(2,24)\n",
    "    cyclops.line_v(3,23,3)\n",
    "    cyclops.line_v(4,22,5)\n",
    "    cyclops.line_v(5,21,7)\n",
    "    cyclops.line_v(6,20,9)\n",
    "    cyclops.line_v(7,19,11)\n",
    "    cyclops.line_v(8,18,13)\n",
    "    cyclops.line_v(9,17,15)\n",
    "    cyclops.line_v(10,16,17)\n",
    "    cyclops.line_v(11,15,19)\n",
    "    cyclops.line_v(12,14,21)\n",
    "    cyclops.line_v(13,13,23)\n",
    "    cyclops.line_v(14,12,25)\n",
    "    cyclops.line_v(15,11,27)\n",
    "    cyclops.line_v(16,10,29)\n",
    "    cyclops.line_v(17,9,31)\n",
    "    cyclops.line_v(18,8,33)\n",
    "    cyclops.line_v(19,7,35)\n",
    "    cyclops.line_v(20,6,37)\n",
    "    \n",
    "    cyclops.rect_fill(20,16,24,16)\n",
    "    \n",
    "    cyclops.display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define sliders to control JetBot\n",
    "> Note: We have initialize the slider values for best known configurations, however these might not work for your dataset, therefore please increase or decrease the sliders according to your setup and environment\n",
    "\n",
    "1. Speed Control (speed_gain_slider): To start your JetBot increase ``speed_gain_slider`` \n",
    "2. Steering Gain Control (steering_gain_sloder): If you see JetBot is woblling, you need to reduce ``steering_gain_slider`` till it is smooth\n",
    "3. Steering Bias control (steering_bias_slider): If you see JetBot is biased towards extreme right or extreme left side of the track, you should control this slider till JetBot start following line or track in the center.  This accounts for motor biases as well as camera offsets\n",
    "\n",
    "> Note: You should play around above mentioned sliders with lower speed to get smooth JetBot road following behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0eaa4825744293b0f1933cd32aa0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='speed gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d321fa9602420e885af5bf7989cc5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.2, description='steering gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89afb702bfeb4b419291a59a7d0d1286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering kd', max=0.5, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f96b6e9ea6498a92f79bb2dfca8787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering bias', max=0.3, min=-0.3, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed gain')\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.2, description='steering gain')\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.0, description='steering kd')\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's display some sliders that will let us see what JetBot is thinking.  The x and y sliders will display the predicted x, y values.\n",
    "\n",
    "The steering slider will display our estimated steering value.  Please remember, this value isn't the actual angle of the target, but simply a value that is\n",
    "nearly proportional.  When the actual angle is ``0``, this will be zero, and it will increase / decrease with the actual angle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a42ed254724f9b8fceb246bdef2c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.0, description='y', max=1.0, orientation='vertical'), FloatSlider(value=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c56e8f98aec428496c99f1f81bf57d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='x', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85b2c997d474d378e4424b87cc12c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "display(ipywidgets.HBox([y_slider, speed_slider]))\n",
    "display(x_slider, steering_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a function that will get called whenever the camera's value changes. This function will do the following steps\n",
    "\n",
    "1. Pre-process the camera image\n",
    "2. Execute the neural network\n",
    "3. Compute the approximate steering value\n",
    "4. Control the motors using proportional / derivative control (PD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last\n",
    "    image = change['new']\n",
    "    xy = model(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "    x = xy[0]\n",
    "    y = (0.5 - xy[1]) / 2.0\n",
    "    \n",
    "    x_slider.value = x\n",
    "    y_slider.value = y\n",
    "    \n",
    "    speed_slider.value = speed_gain_slider.value\n",
    "    \n",
    "    angle = np.arctan2(x, y)\n",
    "    pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "    angle_last = angle\n",
    "    \n",
    "    steering_slider.value = pid + steering_bias_slider.value\n",
    "    \n",
    "    test_val_left  = max(min(speed_slider.value + steering_slider.value, 1.0), 0.0)\n",
    "    test_val_right = max(min(speed_slider.value - steering_slider.value, 1.0), 0.0)\n",
    "    \n",
    "    if abs(test_val_right-test_val_left) < 0.20 :\n",
    "        arrow_straight()\n",
    "    elif test_val_right > test_val_left :\n",
    "        arrow_left()\n",
    "    else :\n",
    "        arrow_right()\n",
    "    \n",
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We've created our neural network execution function, but now we need to attach it to the camera for processing.\n",
    "\n",
    "We accomplish that with the observe function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! If your robot is plugged in it should now be generating new commands with each new camera frame. \n",
    "\n",
    "You can now place JetBot on  Lego or Track you have collected data on and see whether it can follow track.\n",
    "\n",
    "If you want to stop this behavior, you can unattach this callback by executing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT!! The following cell must be exectuted in order to return functionality of your LED screen. It should not be necessary to reboot your robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ······\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "password = getpass.getpass()\n",
    "os.system('echo %s | sudo -S mv  /usr/local/lib/python3.6/dist-packages/jetbot-0.4.0-py3.6.egg/jetbot/apps/stats.py.orig /usr/local/lib/python3.6/dist-packages/jetbot-0.4.0-py3.6.egg/jetbot/apps/stats.py ' % (password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "That's it for this debugging demo! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
